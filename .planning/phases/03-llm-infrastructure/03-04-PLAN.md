---
phase: 03-llm-infrastructure
plan: 04
type: execute
wave: 1
depends_on: []
files_modified:
  - src/features/conversations/conversations.types.ts
  - src/features/conversations/conversations.service.ts
  - src/features/conversations/conversations.routes.ts
  - src/features/conversations/index.ts
  - src/index.ts
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "Agent can retrieve relevant context for conversations"
    - "Conversations are stored with message history"
    - "Old messages are summarized to semantic memory"
    - "Agent maintains knowledge of project context and history across conversations"
  artifacts:
    - path: "src/features/conversations/conversations.service.ts"
      provides: "Conversation handling with context assembly"
      exports: ["createConversation", "addMessage", "getConversationContext", "getMessages"]
    - path: "src/features/conversations/conversations.routes.ts"
      provides: "REST API endpoints for conversations"
      contains: "POST /conversations"
    - path: "src/features/conversations/conversations.types.ts"
      provides: "Type definitions for conversation operations"
      exports: ["CreateConversationInput", "AddMessageInput", "ConversationContext"]
  key_links:
    - from: "src/features/conversations/conversations.service.ts"
      to: "src/features/rag/rag.service.ts"
      via: "RAG retrieval for context"
      pattern: "findSimilarDocuments"
    - from: "src/features/conversations/conversations.service.ts"
      to: "src/features/memory/memory.service.ts"
      via: "Memory retrieval"
      pattern: "retrieveMemories"
    - from: "src/features/conversations/conversations.service.ts"
      to: "src/features/llm/llm.service.ts"
      via: "LLM chat completion"
      pattern: "chatCompletionForOrg"
    - from: "src/features/conversations/conversations.service.ts"
      to: "src/shared/lib/queue/client.ts"
      via: "Memory consolidation trigger"
      pattern: "memoryConsolidationQueue.add"
---

<objective>
Create the conversations service and API routes that wire together RAG, memory, and LLM services.

Purpose: Close the critical gap identified in VERIFICATION.md - the conversations service is the keystone that enables the agent to use the LLM infrastructure. Without it, all LLM components exist but cannot be used for actual conversations.

Output: Full conversations feature with createConversation, addMessage, getConversationContext, and REST API endpoints.
</objective>

<execution_context>
@/Users/dio/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dio/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-llm-infrastructure/03-CONTEXT.md
@.planning/phases/03-llm-infrastructure/03-VERIFICATION.md
@src/features/llm/llm.service.ts
@src/features/rag/rag.service.ts
@src/features/memory/memory.service.ts
@src/shared/db/schema/conversations.ts
@src/shared/lib/queue/client.ts
@src/features/visibility/visibility.service.ts
@src/features/auth/auth.routes.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Conversations Types</name>
  <files>src/features/conversations/conversations.types.ts</files>
  <action>
Create src/features/conversations/conversations.types.ts with:

```typescript
import type { ChatMessage } from '../llm/llm.types';

/** Input for creating a new conversation */
export type CreateConversationInput = {
  organizationId: string;
  userId: string;
  projectId?: string;
  title?: string;
  metadata?: Record<string, unknown>;
};

/** Input for adding a message to a conversation */
export type AddMessageInput = {
  conversationId: string;
  role: 'user' | 'assistant' | 'system';
  content: string;
  metadata?: Record<string, unknown>;
};

/** Context assembled for LLM conversation */
export type ConversationContext = {
  /** System message with assembled context */
  systemMessage: string;
  /** Recent conversation messages */
  recentMessages: ChatMessage[];
  /** RAG documents included in context */
  ragDocuments: Array<{
    content: string;
    sourceType: string;
    sourceId: string;
    similarity: number;
  }>;
  /** Memories included in context */
  memories: Array<{
    content: string;
    type: string;
    scope: string;
  }>;
};

/** Response from sendMessage including context and LLM response */
export type SendMessageResponse = {
  /** The assistant's response message */
  message: {
    id: string;
    role: 'assistant';
    content: string;
    createdAt: Date;
  };
  /** Context that was assembled for this response */
  context: {
    ragDocumentsUsed: number;
    memoriesUsed: number;
  };
  /** Token usage from LLM */
  usage: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
};

/** Message count threshold to trigger consolidation */
export const CONSOLIDATION_THRESHOLD = 20;
```

This follows existing type patterns (see llm.types.ts, memory.types.ts).
  </action>
  <verify>bun run typecheck</verify>
  <done>Conversation types defined with input/output shapes for all service functions</done>
</task>

<task type="auto">
  <name>Task 2: Create Conversations Service</name>
  <files>src/features/conversations/conversations.service.ts</files>
  <action>
Create src/features/conversations/conversations.service.ts with the following functions:

```typescript
import { asc, desc, eq, sql } from 'drizzle-orm';
import { db } from '../../shared/db';
import { conversationMessages, conversations } from '../../shared/db/schema';
import { memoryConsolidationQueue } from '../../shared/lib/queue';
import { chatCompletionForOrg } from '../llm';
import type { ChatMessage } from '../llm/llm.types';
import { retrieveMemories } from '../memory';
import { findSimilarDocuments } from '../rag';
import type {
  AddMessageInput,
  ConversationContext,
  CreateConversationInput,
  CONSOLIDATION_THRESHOLD,
  SendMessageResponse,
} from './conversations.types';

/**
 * Creates a new conversation.
 */
export async function createConversation(input: CreateConversationInput): Promise<string> {
  const result = await db
    .insert(conversations)
    .values({
      organizationId: input.organizationId,
      userId: input.userId,
      projectId: input.projectId,
      title: input.title,
      metadata: input.metadata,
    })
    .returning({ id: conversations.id });

  const conversation = result[0];
  if (!conversation) {
    throw new Error('Failed to create conversation');
  }

  return conversation.id;
}

/**
 * Adds a message to a conversation.
 */
export async function addMessage(input: AddMessageInput): Promise<string> {
  const result = await db
    .insert(conversationMessages)
    .values({
      conversationId: input.conversationId,
      role: input.role,
      content: input.content,
      metadata: input.metadata,
    })
    .returning({ id: conversationMessages.id });

  const message = result[0];
  if (!message) {
    throw new Error('Failed to add message');
  }

  return message.id;
}

/**
 * Retrieves messages for a conversation.
 */
export async function getMessages(conversationId: string, limit = 50) {
  return db
    .select()
    .from(conversationMessages)
    .where(eq(conversationMessages.conversationId, conversationId))
    .orderBy(asc(conversationMessages.createdAt))
    .limit(limit);
}

/**
 * Gets a conversation by ID with owner verification.
 */
export async function getConversation(conversationId: string, userId: string) {
  const conversation = await db.query.conversations.findFirst({
    where: eq(conversations.id, conversationId),
  });

  if (!conversation) {
    return null;
  }

  // Verify ownership
  if (conversation.userId !== userId) {
    return null;
  }

  return conversation;
}

/**
 * Assembles context for a conversation by retrieving RAG documents and memories.
 *
 * CRITICAL: visibleProjectIds must come from user's visibility context for security.
 */
export async function getConversationContext(
  conversationId: string,
  query: string,
  organizationId: string,
  userId: string,
  visibleProjectIds: string[],
  projectId?: string
): Promise<ConversationContext> {
  // 1. Get recent messages from conversation
  const messages = await getMessages(conversationId, 20);
  const recentMessages: ChatMessage[] = messages.map((m) => ({
    role: m.role as 'user' | 'assistant' | 'system',
    content: m.content,
  }));

  // 2. Retrieve similar documents via RAG (respects visibility)
  const ragDocs = await findSimilarDocuments(query, visibleProjectIds, { limit: 5 });

  // 3. Retrieve relevant memories (hierarchical: org -> project -> user)
  const orgMemories = await retrieveMemories({
    organizationId,
    types: ['semantic', 'episodic'],
    limit: 5,
  });

  const projectMemories = projectId
    ? await retrieveMemories({
        organizationId,
        projectId,
        types: ['semantic', 'episodic'],
        limit: 5,
      })
    : [];

  const userMemories = await retrieveMemories({
    organizationId,
    userId,
    types: ['semantic', 'episodic'],
    limit: 5,
  });

  // Combine and dedupe memories
  const allMemories = [...orgMemories, ...projectMemories, ...userMemories];
  const uniqueMemories = allMemories.filter(
    (m, i, arr) => arr.findIndex((x) => x.id === m.id) === i
  );

  // 4. Assemble system message with context
  const systemParts = [
    'You are a helpful project management assistant. You have access to project context and conversation history.',
    '',
  ];

  if (ragDocs.length > 0) {
    systemParts.push('## Relevant Documents');
    for (const doc of ragDocs) {
      systemParts.push(`[${doc.sourceType}] ${doc.content}`);
    }
    systemParts.push('');
  }

  if (uniqueMemories.length > 0) {
    systemParts.push('## Memories');
    for (const mem of uniqueMemories) {
      systemParts.push(`[${mem.scope}/${mem.type}] ${mem.content}`);
    }
    systemParts.push('');
  }

  systemParts.push(
    '## Guidelines',
    '- Use the provided context to give accurate, helpful responses',
    '- If asked about something outside your knowledge, politely explain limitations',
    '- For write operations, clearly describe what will be changed before proceeding'
  );

  return {
    systemMessage: systemParts.join('\n'),
    recentMessages,
    ragDocuments: ragDocs.map((d) => ({
      content: d.content,
      sourceType: d.sourceType,
      sourceId: d.sourceId,
      similarity: d.similarity,
    })),
    memories: uniqueMemories.map((m) => ({
      content: m.content,
      type: m.type,
      scope: m.scope,
    })),
  };
}

/**
 * Sends a user message and gets an AI response.
 * This is the main entry point that wires context assembly + LLM.
 */
export async function sendMessage(
  conversationId: string,
  userMessage: string,
  organizationId: string,
  userId: string,
  visibleProjectIds: string[],
  projectId?: string
): Promise<SendMessageResponse> {
  // 1. Store user message
  await addMessage({
    conversationId,
    role: 'user',
    content: userMessage,
  });

  // 2. Assemble context
  const context = await getConversationContext(
    conversationId,
    userMessage,
    organizationId,
    userId,
    visibleProjectIds,
    projectId
  );

  // 3. Build messages for LLM
  const llmMessages: ChatMessage[] = [
    { role: 'system', content: context.systemMessage },
    ...context.recentMessages,
    { role: 'user', content: userMessage },
  ];

  // 4. Call LLM with org's model preference
  const result = await chatCompletionForOrg(organizationId, llmMessages);

  // 5. Store assistant response
  const messageId = await addMessage({
    conversationId,
    role: 'assistant',
    content: result.content,
  });

  // 6. Check if consolidation needed
  await checkAndTriggerConsolidation(conversationId, organizationId, projectId, userId);

  // 7. Get the stored message for response
  const storedMessage = await db.query.conversationMessages.findFirst({
    where: eq(conversationMessages.id, messageId),
  });

  return {
    message: {
      id: messageId,
      role: 'assistant',
      content: result.content,
      createdAt: storedMessage?.createdAt ?? new Date(),
    },
    context: {
      ragDocumentsUsed: context.ragDocuments.length,
      memoriesUsed: context.memories.length,
    },
    usage: result.usage,
  };
}

/**
 * Checks message count and triggers consolidation if threshold exceeded.
 */
async function checkAndTriggerConsolidation(
  conversationId: string,
  organizationId: string,
  projectId: string | undefined,
  userId: string
): Promise<void> {
  const countResult = await db
    .select({ count: sql<number>`count(*)::int` })
    .from(conversationMessages)
    .where(eq(conversationMessages.conversationId, conversationId));

  const count = countResult[0]?.count ?? 0;

  // Import threshold from types (avoid circular dep by using constant)
  const THRESHOLD = 20;

  if (count >= THRESHOLD) {
    await memoryConsolidationQueue.add(
      `consolidate-${conversationId}`,
      {
        conversationId,
        organizationId,
        projectId,
        userId,
      },
      {
        // Dedup: don't queue if already pending
        jobId: `consolidate-${conversationId}`,
      }
    );
  }
}

/**
 * Lists conversations for a user.
 */
export async function listConversations(
  userId: string,
  organizationId: string,
  limit = 20,
  offset = 0
) {
  return db
    .select({
      id: conversations.id,
      title: conversations.title,
      projectId: conversations.projectId,
      createdAt: conversations.createdAt,
      updatedAt: conversations.updatedAt,
    })
    .from(conversations)
    .where(eq(conversations.userId, userId))
    .orderBy(desc(conversations.updatedAt))
    .limit(limit)
    .offset(offset);
}
```

Key wiring:
- getConversationContext calls findSimilarDocuments (RAG) with visibleProjectIds for security
- getConversationContext calls retrieveMemories (memory) for hierarchical context
- sendMessage calls chatCompletionForOrg (LLM) with assembled context
- checkAndTriggerConsolidation calls memoryConsolidationQueue.add to trigger worker
  </action>
  <verify>bun run typecheck</verify>
  <done>Conversations service created with RAG, memory, and LLM wiring</done>
</task>

<task type="auto">
  <name>Task 3: Create Conversations Routes and Register</name>
  <files>
    src/features/conversations/conversations.routes.ts
    src/features/conversations/index.ts
    src/index.ts
  </files>
  <action>
1. Create src/features/conversations/conversations.routes.ts:

```typescript
import { zValidator } from '@hono/zod-validator';
import { Hono } from 'hono';
import { z } from 'zod';
import { ApiError } from '../../shared/middleware/error-handler';
import { authMiddleware } from '../auth/auth.middleware';
import { visibilityMiddleware } from '../visibility/visibility.middleware';
import { buildVisibilityContext } from '../visibility/visibility.service';
import {
  createConversation,
  getConversation,
  getMessages,
  listConversations,
  sendMessage,
} from './conversations.service';

const conversationsRouter = new Hono();

// All routes require auth + visibility context
conversationsRouter.use('*', authMiddleware);
conversationsRouter.use('*', visibilityMiddleware);

// Validation schemas
const createConversationSchema = z.object({
  projectId: z.string().uuid().optional(),
  title: z.string().max(255).optional(),
});

const sendMessageSchema = z.object({
  content: z.string().min(1).max(32000),
});

// POST /conversations - Create new conversation
conversationsRouter.post('/', zValidator('json', createConversationSchema), async (c) => {
  const user = c.get('user');
  const body = c.req.valid('json');

  const conversationId = await createConversation({
    organizationId: user.org,
    userId: user.sub,
    projectId: body.projectId,
    title: body.title,
  });

  return c.json({ id: conversationId }, 201);
});

// GET /conversations - List user's conversations
conversationsRouter.get('/', async (c) => {
  const user = c.get('user');
  const limit = Math.min(Number(c.req.query('limit')) || 20, 100);
  const offset = Number(c.req.query('offset')) || 0;

  const convos = await listConversations(user.sub, user.org, limit, offset);

  return c.json({ data: convos });
});

// GET /conversations/:id - Get conversation with messages
conversationsRouter.get('/:id', async (c) => {
  const user = c.get('user');
  const conversationId = c.req.param('id');

  const conversation = await getConversation(conversationId, user.sub);
  if (!conversation) {
    throw new ApiError(
      404,
      'conversations/not-found',
      'Conversation Not Found',
      'The conversation does not exist or you do not have access'
    );
  }

  const messages = await getMessages(conversationId);

  return c.json({
    id: conversation.id,
    title: conversation.title,
    projectId: conversation.projectId,
    createdAt: conversation.createdAt,
    updatedAt: conversation.updatedAt,
    messages: messages.map((m) => ({
      id: m.id,
      role: m.role,
      content: m.content,
      createdAt: m.createdAt,
    })),
  });
});

// POST /conversations/:id/messages - Send message and get response
conversationsRouter.post(
  '/:id/messages',
  zValidator('json', sendMessageSchema),
  async (c) => {
    const user = c.get('user');
    const conversationId = c.req.param('id');
    const { content } = c.req.valid('json');

    // Verify conversation exists and user owns it
    const conversation = await getConversation(conversationId, user.sub);
    if (!conversation) {
      throw new ApiError(
        404,
        'conversations/not-found',
        'Conversation Not Found',
        'The conversation does not exist or you do not have access'
      );
    }

    // Get user's visible projects for RAG query security
    const visibilityContext = await buildVisibilityContext(user.sub, user.org);

    const response = await sendMessage(
      conversationId,
      content,
      user.org,
      user.sub,
      visibilityContext.visibleProjectIds,
      conversation.projectId ?? undefined
    );

    return c.json(response, 201);
  }
);

export { conversationsRouter as conversationRoutes };
```

2. Create src/features/conversations/index.ts:

```typescript
export * from './conversations.types';
export {
  createConversation,
  addMessage,
  getMessages,
  getConversation,
  getConversationContext,
  sendMessage,
  listConversations,
} from './conversations.service';
export { conversationRoutes } from './conversations.routes';
```

3. Update src/index.ts to register the routes:

Add import at top:
```typescript
import { conversationRoutes } from './features/conversations';
```

Add route registration after other feature routes (around line 89-90):
```typescript
app.route('/api/v1/conversations', conversationRoutes);
```

The routes follow existing patterns from auth.routes.ts:
- Use zValidator for request validation
- Use authMiddleware for JWT auth
- Use visibilityMiddleware for CASL abilities
- Return proper error responses with ApiError
- Follow REST conventions (POST for create, GET for read)
  </action>
  <verify>bun run typecheck && bun run lint</verify>
  <done>Conversations routes registered with auth/visibility middleware, API endpoints available</done>
</task>

</tasks>

<verification>
1. TypeScript: `bun run typecheck` passes
2. Lint: `bun run lint` passes
3. Files exist:
   - src/features/conversations/conversations.types.ts
   - src/features/conversations/conversations.service.ts
   - src/features/conversations/conversations.routes.ts
   - src/features/conversations/index.ts
4. Routes registered in src/index.ts
5. Key links verified:
   - conversations.service.ts imports and calls findSimilarDocuments
   - conversations.service.ts imports and calls retrieveMemories
   - conversations.service.ts imports and calls chatCompletionForOrg
   - conversations.service.ts imports and calls memoryConsolidationQueue.add
</verification>

<success_criteria>
- Conversations can be created via POST /api/v1/conversations
- Messages can be sent via POST /api/v1/conversations/:id/messages
- Messages retrieve context from RAG (findSimilarDocuments) and memory (retrieveMemories)
- Messages are sent to LLM via chatCompletionForOrg with assembled context
- Conversation history is stored in database
- Memory consolidation is triggered when message count exceeds threshold
- All routes protected by auth + visibility middleware
- Visible project IDs passed to RAG for security
</success_criteria>

<output>
After completion, create `.planning/phases/03-llm-infrastructure/03-04-SUMMARY.md`
</output>
