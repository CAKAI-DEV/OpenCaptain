---
phase: 01-core-infrastructure
plan: 03
type: execute
wave: 3
depends_on: ["01-02"]
files_modified:
  - src/middleware/rate-limit.ts
  - src/routes/health/index.ts
  - src/routes/index.ts
  - src/index.ts
  - docker-compose.yml
  - docker-compose.prod.yml
  - Dockerfile
  - .dockerignore
  - .env.example
  - DEPLOYMENT.md
autonomous: false

must_haves:
  truths:
    - "Rate limiting blocks excessive requests with 429 response"
    - "Health endpoint reports database and Redis connectivity"
    - "Docker Compose builds and runs the full stack"
    - "Traefik provides auto SSL in production profile"
    - "System starts successfully on docker compose up"
    - "Documentation covers VPS deployment end-to-end"
  artifacts:
    - path: "src/middleware/rate-limit.ts"
      provides: "Redis-based sliding window rate limiter"
      contains: "sorted set"
    - path: "docker-compose.prod.yml"
      provides: "Production Docker Compose with Traefik"
      contains: "traefik"
    - path: "Dockerfile"
      provides: "Multi-stage build for Bun application"
      contains: "FROM oven/bun"
    - path: "DEPLOYMENT.md"
      provides: "VPS deployment documentation"
      contains: "docker compose"
  key_links:
    - from: "src/middleware/rate-limit.ts"
      to: "src/lib/redis.ts"
      via: "Redis sorted set operations"
      pattern: "redis\\.(zadd|zremrangebyscore|zcard)"
    - from: "docker-compose.prod.yml"
      to: "Dockerfile"
      via: "build context"
      pattern: "build:"
---

<objective>
Complete API gateway with rate limiting and production-ready Docker deployment.

Purpose: Make the system deployable on a VPS with proper rate limiting, health monitoring, and SSL termination. This completes Phase 1's goal of a deployable, accessible system with authentication.

Output: Rate limiting middleware, comprehensive health checks, Docker Compose production setup with Traefik, and deployment documentation.
</objective>

<execution_context>
@/Users/dio/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dio/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-core-infrastructure/01-CONTEXT.md
@.planning/phases/01-core-infrastructure/01-RESEARCH.md
@.planning/phases/01-core-infrastructure/01-01-SUMMARY.md
@.planning/phases/01-core-infrastructure/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement rate limiting and health checks</name>
  <files>
    src/middleware/rate-limit.ts
    src/routes/health/index.ts
    src/routes/index.ts
    src/index.ts
  </files>
  <action>
Create Redis-based rate limiting with sliding window algorithm and comprehensive health checks:

**Create src/middleware/rate-limit.ts**:
```typescript
import { Context, Next } from 'hono';
import { redis } from '../lib/redis';
import { ApiError } from './error-handler';
import { logger } from '../lib/logger';

interface RateLimitConfig {
  windowMs: number;     // Window size in milliseconds
  maxRequests: number;  // Max requests per window
  keyPrefix: string;    // Redis key prefix
}

const DEFAULT_CONFIG: RateLimitConfig = {
  windowMs: 60 * 1000,    // 1 minute
  maxRequests: 100,        // 100 requests per minute
  keyPrefix: 'ratelimit',
};

// Lua script for atomic rate limiting with sliding window
const SLIDING_WINDOW_SCRIPT = `
local key = KEYS[1]
local now = tonumber(ARGV[1])
local window = tonumber(ARGV[2])
local limit = tonumber(ARGV[3])

-- Remove old entries outside the window
redis.call('ZREMRANGEBYSCORE', key, '-inf', now - window)

-- Count current entries
local count = redis.call('ZCARD', key)

if count >= limit then
  return {0, count, limit}
end

-- Add current request
redis.call('ZADD', key, now, now .. '-' .. math.random())

-- Set expiry on key
redis.call('PEXPIRE', key, window)

return {1, count + 1, limit}
`;

export function createRateLimiter(config: Partial<RateLimitConfig> = {}) {
  const { windowMs, maxRequests, keyPrefix } = { ...DEFAULT_CONFIG, ...config };

  return async function rateLimitMiddleware(c: Context, next: Next) {
    // Get identifier: user ID if authenticated, IP otherwise
    const user = c.get('user');
    const identifier = user?.sub || c.req.header('x-forwarded-for') || 'anonymous';

    const key = `${keyPrefix}:${identifier}`;
    const now = Date.now();

    try {
      const result = await redis.eval(SLIDING_WINDOW_SCRIPT, {
        keys: [key],
        arguments: [now.toString(), windowMs.toString(), maxRequests.toString()],
      }) as [number, number, number];

      const [allowed, current, limit] = result;

      // Set rate limit headers
      c.header('X-RateLimit-Limit', limit.toString());
      c.header('X-RateLimit-Remaining', Math.max(0, limit - current).toString());
      c.header('X-RateLimit-Reset', Math.ceil((now + windowMs) / 1000).toString());

      if (!allowed) {
        throw new ApiError(
          429,
          'rate-limit/exceeded',
          'Rate Limit Exceeded',
          `Too many requests. Please try again in ${Math.ceil(windowMs / 1000)} seconds.`
        );
      }

      await next();
    } catch (err) {
      if (err instanceof ApiError) throw err;

      // If Redis fails, log and allow request (fail open for availability)
      logger.error({ err, key }, 'Rate limiter Redis error, allowing request');
      await next();
    }
  };
}

// Pre-configured rate limiters
export const apiRateLimiter = createRateLimiter({
  windowMs: 60 * 1000,   // 1 minute
  maxRequests: 100,       // 100 requests/min per user
  keyPrefix: 'ratelimit:api',
});

export const authRateLimiter = createRateLimiter({
  windowMs: 15 * 60 * 1000, // 15 minutes
  maxRequests: 10,           // 10 attempts per 15 min
  keyPrefix: 'ratelimit:auth',
});
```

**Create src/routes/health/index.ts**:
```typescript
import { Hono } from 'hono';
import { db } from '../../db';
import { redis } from '../../lib/redis';
import { sql } from 'drizzle-orm';
import { logger } from '../../lib/logger';

const app = new Hono();

interface HealthCheck {
  status: 'healthy' | 'unhealthy';
  latency?: number;
  error?: string;
}

interface HealthResponse {
  status: 'healthy' | 'degraded' | 'unhealthy';
  timestamp: string;
  version: string;
  checks: {
    database: HealthCheck;
    redis: HealthCheck;
  };
}

async function checkDatabase(): Promise<HealthCheck> {
  const start = Date.now();
  try {
    await db.execute(sql`SELECT 1`);
    return { status: 'healthy', latency: Date.now() - start };
  } catch (err) {
    logger.error({ err }, 'Database health check failed');
    return { status: 'unhealthy', error: 'Connection failed' };
  }
}

async function checkRedis(): Promise<HealthCheck> {
  const start = Date.now();
  try {
    await redis.ping();
    return { status: 'healthy', latency: Date.now() - start };
  } catch (err) {
    logger.error({ err }, 'Redis health check failed');
    return { status: 'unhealthy', error: 'Connection failed' };
  }
}

// Detailed health check (for monitoring)
app.get('/', async (c) => {
  const [database, redisCheck] = await Promise.all([
    checkDatabase(),
    checkRedis(),
  ]);

  const allHealthy = database.status === 'healthy' && redisCheck.status === 'healthy';
  const allUnhealthy = database.status === 'unhealthy' && redisCheck.status === 'unhealthy';

  const response: HealthResponse = {
    status: allUnhealthy ? 'unhealthy' : allHealthy ? 'healthy' : 'degraded',
    timestamp: new Date().toISOString(),
    version: process.env.npm_package_version || '0.0.0',
    checks: {
      database,
      redis: redisCheck,
    },
  };

  const statusCode = response.status === 'unhealthy' ? 503 : 200;
  return c.json(response, statusCode);
});

// Simple liveness probe (for Kubernetes/Docker)
app.get('/live', (c) => {
  return c.json({ status: 'ok' });
});

// Readiness probe (for Kubernetes/Docker)
app.get('/ready', async (c) => {
  const [database, redisCheck] = await Promise.all([
    checkDatabase(),
    checkRedis(),
  ]);

  if (database.status === 'unhealthy' || redisCheck.status === 'unhealthy') {
    return c.json({ status: 'not ready' }, 503);
  }

  return c.json({ status: 'ready' });
});

export default app;
```

**Update src/routes/index.ts** to include health routes:
```typescript
import { Hono } from 'hono';
import auth from './auth';
import health from './health';

const app = new Hono();

app.route('/auth', auth);
app.route('/health', health);

export default app;
```

**Update src/index.ts** to apply rate limiting:
```typescript
import { Hono } from 'hono';
import { cors } from 'hono/cors';
import { env } from './lib/env';
import { logger } from './lib/logger';
import { connectRedis } from './lib/redis';
import { errorHandler } from './middleware/error-handler';
import { apiRateLimiter, authRateLimiter } from './middleware/rate-limit';
import routes from './routes';

const app = new Hono();

// Global middleware
app.use('*', cors({ origin: env.CORS_ORIGIN, credentials: true }));
app.use('*', errorHandler);

// Health checks (no rate limiting)
app.get('/health', async (c) => {
  return c.json({ status: 'ok', timestamp: new Date().toISOString() });
});

// Auth routes with stricter rate limiting
app.use('/api/v1/auth/*', authRateLimiter);

// All API routes with standard rate limiting
app.use('/api/v1/*', apiRateLimiter);

// API routes
app.route('/api/v1', routes);

// Start server
async function main() {
  await connectRedis();
  logger.info({ port: env.PORT }, 'Starting BlockBot API');

  Bun.serve({
    port: env.PORT,
    fetch: app.fetch,
  });

  logger.info({ port: env.PORT }, 'BlockBot API started');
}

main().catch((err) => {
  logger.fatal({ err }, 'Failed to start server');
  process.exit(1);
});
```
  </action>
  <verify>
Test rate limiting:
```bash
# Make 11 rapid auth requests (should get rate limited)
for i in {1..11}; do
  curl -s -o /dev/null -w "%{http_code}\n" \
    -X POST http://localhost:3000/api/v1/auth/login \
    -H "Content-Type: application/json" \
    -d '{"email":"x@x.com","password":"x"}'
done
```
11th request should return 429

Test health endpoints:
```bash
curl http://localhost:3000/api/v1/health
curl http://localhost:3000/api/v1/health/live
curl http://localhost:3000/api/v1/health/ready
```
All should return 200 with appropriate JSON
  </verify>
  <done>
    Rate limiting returns 429 after limit exceeded, health endpoints report database and Redis status correctly
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Docker production setup with Traefik</name>
  <files>
    Dockerfile
    .dockerignore
    docker-compose.yml
    docker-compose.prod.yml
    .env.example
  </files>
  <action>
Create production-ready Docker configuration:

**Create Dockerfile** (multi-stage build for Bun):
```dockerfile
# Build stage
FROM oven/bun:1.2-alpine AS builder

WORKDIR /app

# Copy package files
COPY package.json bun.lockb ./

# Install dependencies
RUN bun install --frozen-lockfile --production=false

# Copy source
COPY . .

# Build (if needed - Bun can run TS directly, but we can prebuild)
RUN bun build src/index.ts --target=bun --outdir=dist

# Production stage
FROM oven/bun:1.2-alpine AS runner

WORKDIR /app

# Create non-root user
RUN addgroup -g 1001 -S blockbot && \
    adduser -S blockbot -u 1001 -G blockbot

# Copy built application
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/node_modules ./node_modules
COPY --from=builder /app/package.json ./
COPY --from=builder /app/drizzle.config.ts ./
COPY --from=builder /app/src/db ./src/db

# Switch to non-root user
USER blockbot

# Expose port
EXPOSE 3000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD wget --no-verbose --tries=1 --spider http://localhost:3000/health || exit 1

# Start application
CMD ["bun", "run", "dist/index.js"]
```

**Create .dockerignore**:
```
node_modules
dist
.git
.gitignore
.env
.env.local
*.md
!DEPLOYMENT.md
.planning
.vscode
.idea
```

**Update docker-compose.yml** (development):
```yaml
services:
  postgres:
    image: postgres:16-alpine
    container_name: blockbot-postgres
    environment:
      POSTGRES_DB: blockbot
      POSTGRES_USER: blockbot
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-devpassword}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U blockbot -d blockbot"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  redis:
    image: redis:7-alpine
    container_name: blockbot-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  postgres_data:
  redis_data:
```

**Create docker-compose.prod.yml** (production with Traefik):
```yaml
services:
  postgres:
    image: postgres:16-alpine
    container_name: blockbot-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: blockbot
      POSTGRES_USER: blockbot
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U blockbot -d blockbot"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - internal

  redis:
    image: redis:7-alpine
    container_name: blockbot-redis
    restart: unless-stopped
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - internal

  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: blockbot-api
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      DATABASE_URL: postgres://blockbot:${POSTGRES_PASSWORD}@postgres:5432/blockbot
      REDIS_URL: redis://redis:6379
      JWT_SECRET: ${JWT_SECRET}
      JWT_REFRESH_SECRET: ${JWT_REFRESH_SECRET}
      RESEND_API_KEY: ${RESEND_API_KEY}
      NODE_ENV: production
      PORT: 3000
      CORS_ORIGIN: https://${DOMAIN}
      APP_URL: https://${DOMAIN}
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.api.rule=Host(`${DOMAIN}`)"
      - "traefik.http.routers.api.entrypoints=websecure"
      - "traefik.http.routers.api.tls.certresolver=letsencrypt"
      - "traefik.http.services.api.loadbalancer.server.port=3000"
    networks:
      - internal
      - web

  traefik:
    image: traefik:v3.0
    container_name: blockbot-traefik
    restart: unless-stopped
    command:
      - "--api.dashboard=false"
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--providers.docker.network=web"
      - "--entrypoints.web.address=:80"
      - "--entrypoints.websecure.address=:443"
      - "--entrypoints.web.http.redirections.entrypoint.to=websecure"
      - "--entrypoints.web.http.redirections.entrypoint.scheme=https"
      - "--certificatesresolvers.letsencrypt.acme.email=${ACME_EMAIL}"
      - "--certificatesresolvers.letsencrypt.acme.storage=/letsencrypt/acme.json"
      - "--certificatesresolvers.letsencrypt.acme.httpchallenge.entrypoint=web"
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - letsencrypt:/letsencrypt
    networks:
      - web

networks:
  internal:
    driver: bridge
  web:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  letsencrypt:
```

**Update .env.example** with all production variables:
```bash
# Database
DATABASE_URL=postgres://blockbot:password@localhost:5432/blockbot
POSTGRES_PASSWORD=your-secure-postgres-password

# Redis
REDIS_URL=redis://localhost:6379

# Authentication
JWT_SECRET=your-32-character-minimum-secret-key-here
JWT_REFRESH_SECRET=another-32-character-minimum-secret-here

# Email (Resend)
RESEND_API_KEY=re_your_resend_api_key

# Application
NODE_ENV=development
PORT=3000
CORS_ORIGIN=http://localhost:3000
APP_URL=http://localhost:3000

# Production only
DOMAIN=api.yourdomain.com
ACME_EMAIL=admin@yourdomain.com
```
  </action>
  <verify>
Test Docker build:
```bash
docker build -t blockbot-api .
```
Build should complete without errors

Test production compose (without starting Traefik - just validate):
```bash
docker compose -f docker-compose.prod.yml config
```
Should show valid composed configuration
  </verify>
  <done>
    Dockerfile builds successfully, docker-compose.prod.yml validates, all services properly configured
  </done>
</task>

<task type="auto">
  <name>Task 3: Write deployment documentation</name>
  <files>
    DEPLOYMENT.md
  </files>
  <action>
Create comprehensive VPS deployment guide:

**Create DEPLOYMENT.md**:
```markdown
# BlockBot Deployment Guide

This guide covers deploying BlockBot on a VPS with Docker Compose.

## Requirements

- VPS with at least 8GB RAM and 4 CPU cores
- Ubuntu 22.04 or Debian 12 (other Linux distributions work with minor adjustments)
- Root or sudo access
- Domain name pointed to your VPS IP address
- LLM API tokens (OpenAI, Anthropic, or other supported providers)

## Quick Start

### 1. Install Docker

```bash
# Update system
sudo apt update && sudo apt upgrade -y

# Install Docker
curl -fsSL https://get.docker.com | sh

# Add your user to docker group
sudo usermod -aG docker $USER

# Log out and back in, then verify
docker --version
docker compose version
```

### 2. Clone Repository

```bash
git clone https://github.com/your-org/blockbot.git
cd blockbot
```

### 3. Configure Environment

```bash
# Copy example environment file
cp .env.example .env

# Edit with your values
nano .env
```

**Required environment variables:**

| Variable | Description | Example |
|----------|-------------|---------|
| `POSTGRES_PASSWORD` | Database password | `your-secure-password` |
| `JWT_SECRET` | 32+ character secret for access tokens | `$(openssl rand -hex 32)` |
| `JWT_REFRESH_SECRET` | 32+ character secret for refresh tokens | `$(openssl rand -hex 32)` |
| `RESEND_API_KEY` | Resend.com API key for emails | `re_xxxxx` |
| `DOMAIN` | Your domain (without https://) | `api.example.com` |
| `ACME_EMAIL` | Email for Let's Encrypt SSL | `admin@example.com` |

**Generate secure secrets:**
```bash
# Generate JWT secrets
echo "JWT_SECRET=$(openssl rand -hex 32)"
echo "JWT_REFRESH_SECRET=$(openssl rand -hex 32)"
echo "POSTGRES_PASSWORD=$(openssl rand -hex 24)"
```

### 4. Deploy

```bash
# Start all services
docker compose -f docker-compose.prod.yml up -d

# Check status
docker compose -f docker-compose.prod.yml ps

# View logs
docker compose -f docker-compose.prod.yml logs -f api
```

### 5. Run Database Migrations

```bash
# Run migrations
docker compose -f docker-compose.prod.yml exec api bun run db:migrate
```

### 6. Verify Deployment

```bash
# Check health endpoint
curl https://your-domain.com/api/v1/health

# Expected response:
# {"status":"healthy","timestamp":"...","version":"...","checks":{...}}
```

## Configuration

### LLM API Tokens

BlockBot uses a bring-your-own-token (BYOT) model. Add your LLM API keys to `.env`:

```bash
# OpenAI
OPENAI_API_KEY=sk-xxxxx

# Anthropic (Claude)
ANTHROPIC_API_KEY=sk-ant-xxxxx

# Or use LiteLLM proxy (configured in Phase 3)
LITELLM_API_BASE=http://litellm:4000
```

### Email Configuration

BlockBot uses [Resend](https://resend.com) for transactional emails (magic links, notifications).

1. Create account at resend.com
2. Add and verify your sending domain
3. Generate API key
4. Add to `.env`: `RESEND_API_KEY=re_xxxxx`

For testing, you can use Resend's default `onboarding@resend.dev` sender.

### SSL Certificates

Traefik automatically obtains and renews SSL certificates from Let's Encrypt.

**Requirements:**
- Domain DNS pointing to your VPS IP
- Ports 80 and 443 open
- Valid email in `ACME_EMAIL`

Certificates are stored in the `letsencrypt` Docker volume.

## Operations

### View Logs

```bash
# All services
docker compose -f docker-compose.prod.yml logs -f

# Specific service
docker compose -f docker-compose.prod.yml logs -f api
docker compose -f docker-compose.prod.yml logs -f postgres
docker compose -f docker-compose.prod.yml logs -f redis
```

### Restart Services

```bash
# Restart all
docker compose -f docker-compose.prod.yml restart

# Restart specific service
docker compose -f docker-compose.prod.yml restart api
```

### Update BlockBot

```bash
# Pull latest code
git pull

# Rebuild and restart
docker compose -f docker-compose.prod.yml up -d --build

# Run any new migrations
docker compose -f docker-compose.prod.yml exec api bun run db:migrate
```

### Backup Database

```bash
# Create backup
docker compose -f docker-compose.prod.yml exec postgres \
  pg_dump -U blockbot blockbot > backup-$(date +%Y%m%d).sql

# Restore backup
docker compose -f docker-compose.prod.yml exec -T postgres \
  psql -U blockbot blockbot < backup-20240101.sql
```

### Scale API (Optional)

For higher load, you can run multiple API instances:

```bash
docker compose -f docker-compose.prod.yml up -d --scale api=3
```

Traefik automatically load balances between instances.

## Troubleshooting

### API Not Starting

```bash
# Check logs
docker compose -f docker-compose.prod.yml logs api

# Common issues:
# - Database not ready: Wait for postgres healthcheck
# - Missing env vars: Check .env file
# - Port conflict: Check nothing else on port 3000
```

### Database Connection Failed

```bash
# Check postgres is healthy
docker compose -f docker-compose.prod.yml ps postgres

# Check DATABASE_URL format
# Should be: postgres://blockbot:PASSWORD@postgres:5432/blockbot
```

### SSL Certificate Issues

```bash
# Check Traefik logs
docker compose -f docker-compose.prod.yml logs traefik

# Common issues:
# - DNS not propagated: Wait or check A record
# - Port 80 blocked: Open firewall
# - Rate limited: Wait 1 hour (Let's Encrypt limit)
```

### Redis Connection Failed

```bash
# Check redis is healthy
docker compose -f docker-compose.prod.yml ps redis

# Test connection
docker compose -f docker-compose.prod.yml exec redis redis-cli ping
```

## Security Checklist

- [ ] Strong passwords for all secrets (use `openssl rand -hex 32`)
- [ ] Firewall allows only ports 80, 443, and SSH
- [ ] SSH key authentication enabled, password auth disabled
- [ ] Regular system updates (`apt update && apt upgrade`)
- [ ] Database backups scheduled (daily recommended)
- [ ] Monitoring configured (optional: use `/api/v1/health` endpoint)

## Minimum System Requirements

| Resource | Minimum | Recommended |
|----------|---------|-------------|
| RAM | 8 GB | 16 GB |
| CPU | 4 cores | 8 cores |
| Storage | 20 GB | 50 GB |
| OS | Ubuntu 22.04 / Debian 12 | Ubuntu 22.04 LTS |

## Support

For issues, please open a GitHub issue with:
- Output of `docker compose -f docker-compose.prod.yml ps`
- Relevant logs from `docker compose logs`
- Your `.env` file (with secrets redacted)
```
  </action>
  <verify>
    `cat DEPLOYMENT.md` shows comprehensive documentation
    Documentation covers: requirements, quick start, configuration, operations, troubleshooting
  </verify>
  <done>
    DEPLOYMENT.md created with complete VPS deployment instructions
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
    Complete Phase 1 infrastructure:
    - PostgreSQL + Redis in Docker with health checks
    - Drizzle ORM with organizations, users, refresh_tokens, magic_links schemas
    - JWT authentication with password login and magic links
    - Rate limiting with Redis sliding window algorithm
    - RFC 7807 error responses
    - Health endpoints (detailed, liveness, readiness)
    - Production Docker Compose with Traefik auto SSL
    - Deployment documentation
  </what-built>
  <how-to-verify>
    1. Start development stack:
       ```bash
       docker compose up -d
       cp .env.example .env  # Fill in values
       bun run db:migrate
       bun run dev
       ```

    2. Test complete auth flow:
       ```bash
       # Register
       curl -X POST http://localhost:3000/api/v1/auth/register \
         -H "Content-Type: application/json" \
         -d '{"email":"test@test.com","password":"password123","orgName":"Test"}'

       # Login (use returned tokens)
       curl -X POST http://localhost:3000/api/v1/auth/login \
         -H "Content-Type: application/json" \
         -d '{"email":"test@test.com","password":"password123"}'
       ```

    3. Test rate limiting (should get 429 on 11th request):
       ```bash
       for i in {1..11}; do
         curl -s -o /dev/null -w "%{http_code} " \
           -X POST http://localhost:3000/api/v1/auth/login \
           -H "Content-Type: application/json" \
           -d '{"email":"x@x.com","password":"x"}'
       done
       ```

    4. Test health endpoints:
       ```bash
       curl http://localhost:3000/api/v1/health
       curl http://localhost:3000/api/v1/health/ready
       ```

    5. Verify Docker build:
       ```bash
       docker build -t blockbot-api .
       ```

    6. Review DEPLOYMENT.md for completeness

    **Expected results:**
    - Register returns 201 with tokens
    - Login returns 200 with tokens
    - 11th rapid request returns 429
    - Health returns "healthy" status with db/redis checks
    - Docker build succeeds
  </how-to-verify>
  <resume-signal>Type "approved" to complete Phase 1, or describe any issues found</resume-signal>
</task>

</tasks>

<verification>
After all tasks complete:
1. Rate limiting returns 429 after 10 auth attempts in 15 minutes
2. Health endpoint at /api/v1/health shows database and Redis status
3. Docker build completes successfully
4. docker-compose.prod.yml validates without errors
5. DEPLOYMENT.md contains complete VPS deployment instructions
6. Human verification confirms end-to-end functionality
</verification>

<success_criteria>
- Rate limiter uses Redis sliding window with Lua script for atomicity
- Health endpoint reports database and Redis connectivity with latency
- Liveness and readiness probes available for container orchestration
- Dockerfile uses multi-stage build with non-root user
- Production compose includes Traefik with auto SSL
- All services have health checks and restart policies
- DEPLOYMENT.md covers requirements through troubleshooting
- System deploys via `docker compose -f docker-compose.prod.yml up -d`
</success_criteria>

<output>
After completion, create `.planning/phases/01-core-infrastructure/01-03-SUMMARY.md`
</output>
