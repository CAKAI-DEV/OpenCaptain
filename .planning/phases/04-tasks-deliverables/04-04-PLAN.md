---
phase: 04-tasks-deliverables
plan: 04
type: execute
wave: 2
depends_on: ["04-01", "04-02"]
files_modified:
  - src/shared/db/schema/attachments.ts
  - src/shared/db/schema/index.ts
  - src/shared/lib/env.ts
  - src/features/uploads/uploads.types.ts
  - src/features/uploads/uploads.service.ts
  - src/features/uploads/uploads.routes.ts
  - src/features/uploads/index.ts
  - src/features/metrics/metrics.types.ts
  - src/features/metrics/metrics.service.ts
  - src/features/metrics/metrics.routes.ts
  - src/features/metrics/index.ts
  - src/index.ts
autonomous: true
user_setup:
  - service: S3-compatible storage
    why: "File upload storage for attachments"
    env_vars:
      - name: S3_ACCESS_KEY_ID
        source: "S3 provider dashboard or MinIO admin console"
      - name: S3_SECRET_ACCESS_KEY
        source: "S3 provider dashboard or MinIO admin console"
      - name: S3_BUCKET
        source: "Create bucket in S3 provider dashboard"
      - name: S3_ENDPOINT
        source: "S3 provider endpoint URL (e.g., https://s3.amazonaws.com or http://localhost:9000 for MinIO)"

must_haves:
  truths:
    - "User can request presigned URL for file upload"
    - "User can confirm upload and get download URL"
    - "User can view output metrics per person, squad, and time period"
    - "Metrics include completed tasks and deliverables count"
    - "Metrics support daily, weekly, monthly granularity"
  artifacts:
    - path: "src/shared/db/schema/attachments.ts"
      provides: "Attachments table for tracking uploads"
      contains: "s3Key"
    - path: "src/features/uploads/uploads.service.ts"
      provides: "S3 presigned URL generation"
      exports: ["createUploadUrl", "confirmUpload", "getDownloadUrl"]
    - path: "src/features/metrics/metrics.service.ts"
      provides: "Output metrics aggregation"
      exports: ["getOutputMetrics", "getVelocity", "getBurndownData"]
  key_links:
    - from: "src/features/uploads/uploads.service.ts"
      to: "Bun S3 Client"
      via: "presign method"
      pattern: "s3\\.presign|S3Client"
    - from: "src/features/metrics/metrics.service.ts"
      to: "src/shared/db/schema/tasks.ts"
      via: "aggregation queries"
      pattern: "count\\(\\)|sql`"
---

<objective>
Implement file upload functionality with S3 presigned URLs and output metrics aggregation for tasks and deliverables.

Purpose: Enable users to attach proof files to deliverables and view productivity metrics across different time periods and groupings.
Output: Attachments schema, S3 presigned URL service, metrics aggregation with velocity and burndown data, REST APIs for both.
</objective>

<execution_context>
@/Users/dio/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dio/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-tasks-deliverables/04-CONTEXT.md
@.planning/phases/04-tasks-deliverables/04-RESEARCH.md

Reference prior plan outputs:
@.planning/phases/04-tasks-deliverables/04-01-SUMMARY.md
@.planning/phases/04-tasks-deliverables/04-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create attachments schema and uploads service</name>
  <files>
    src/shared/db/schema/attachments.ts
    src/shared/db/schema/index.ts
    src/shared/lib/env.ts
    src/features/uploads/uploads.types.ts
    src/features/uploads/uploads.service.ts
    src/features/uploads/index.ts
  </files>
  <action>
Create attachments tracking and S3 presigned URL service:

1. Create `src/shared/db/schema/attachments.ts`:
   - Create attachmentStatusEnum with pgEnum: 'pending', 'completed', 'failed'
   - Create attachments table:
     - id: uuid primary key defaultRandom()
     - targetType: varchar(20) not null ('task' | 'deliverable')
     - targetId: uuid not null
     - filename: varchar(500) not null
     - contentType: varchar(255) not null
     - s3Key: varchar(1000) not null
     - fileSize: integer nullable (set after upload confirmation)
     - status: attachmentStatusEnum not null default 'pending'
     - uploadedById: uuid referencing users.id not null
     - completedAt: timestamp with timezone nullable
     - createdAt: timestamp with timezone defaultNow()

2. Export from `src/shared/db/schema/index.ts`

3. Update `src/shared/lib/env.ts` to add S3 environment variables:
   - S3_ACCESS_KEY_ID: z.string().optional()
   - S3_SECRET_ACCESS_KEY: z.string().optional()
   - S3_BUCKET: z.string().optional()
   - S3_ENDPOINT: z.string().optional()
   All optional since file uploads are an optional feature.

4. Create `src/features/uploads/uploads.types.ts`:
   - CreateUploadInput: { filename, contentType, targetType: 'task' | 'deliverable', targetId }
   - PresignedUploadResult: { uploadUrl: string, attachmentId: string, expiresAt: Date }
   - AttachmentResult: inferred select type

5. Create `src/features/uploads/uploads.service.ts`:
   - Initialize S3Client at module level using env vars (lazy - only if configured)

   - createUploadUrl(input, userId): PresignedUploadResult
     - Check S3 is configured (throw 503 if not)
     - Generate attachmentId with nanoid
     - Build s3Key: `attachments/${targetType}/${targetId}/${attachmentId}/${filename}`
     - Generate presigned PUT URL with 1 hour expiry
     - Insert attachment record with status 'pending'
     - Return { uploadUrl, attachmentId, expiresAt }

   - confirmUpload(attachmentId): string (download URL)
     - Fetch attachment, verify exists and status is 'pending'
     - Check file exists in S3 using Bun's S3 file().exists()
     - If not exists, throw 400 'uploads/file-not-found'
     - Get file size from S3 metadata
     - Update status to 'completed', set fileSize and completedAt
     - Generate presigned GET URL with 7 day expiry
     - Return download URL

   - getDownloadUrl(attachmentId): string
     - Fetch attachment, verify exists and status is 'completed'
     - Generate presigned GET URL with 7 day expiry
     - Return URL

   - deleteAttachment(attachmentId):
     - Fetch attachment, verify exists
     - Delete from S3 using Bun's S3 file().delete()
     - Delete record from database

   - listAttachments(targetType, targetId): AttachmentResult[]
     - Return completed attachments for target

6. Create barrel export
  </action>
  <verify>
Run `bun run typecheck` - no TypeScript errors.
Run `bun run db:generate` - migration generated.
  </verify>
  <done>
Attachments schema and S3 presigned URL service created. Supports upload URL generation, confirmation with existence check, and download URL generation.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create metrics service with aggregation queries</name>
  <files>
    src/features/metrics/metrics.types.ts
    src/features/metrics/metrics.service.ts
    src/features/metrics/index.ts
  </files>
  <action>
Create metrics aggregation service following 04-RESEARCH.md patterns:

1. Install dayjs: `bun add dayjs`

2. Create `src/features/metrics/metrics.types.ts`:
   - OutputMetrics: {
       totalCompleted: number,
       byDay: Array<{ date: string, count: number }>,
       byPerson: Array<{ userId: string, email: string, count: number }>,
       bySquad: Array<{ squadId: string, name: string, count: number }>
     }
   - VelocityPeriod: { periodStart: Date, periodEnd: Date, velocity: number }
   - BurndownPoint: { date: string, remaining: number, ideal: number }
   - MetricsQueryInput: { projectId, startDate, endDate, squadId?, granularity?: 'daily' | 'weekly' | 'monthly' }

3. Create `src/features/metrics/metrics.service.ts`:
   - Import dayjs, sql, eq, and, gte, lte, count from drizzle-orm

   - getOutputMetrics(projectId, startDate, endDate, squadId?): OutputMetrics
     - Count completed tasks: status = 'done' AND completedAt in range
     - Count completed deliverables: completedAt in range (need to check isFinal via join with type config)
     - Use raw SQL for complex aggregations (byDay, byPerson, bySquad)
     - Include both tasks and deliverables in counts
     - Group by date using DATE(completed_at)
     - Group by person using assignee_id with user email join
     - Group by squad using squad_id with squad name join
     - Return structured OutputMetrics

   - getVelocity(projectId, periodDays?: number = 7, numPeriods?: number = 4): VelocityPeriod[]
     - Calculate metrics for each period going backwards from now
     - Use dayjs for date manipulation
     - Return array of { periodStart, periodEnd, velocity }
     - Oldest period first (reversed)

   - getBurndownData(projectId, startDate, endDate, squadId?): BurndownPoint[]
     - Calculate total work items at start date
     - Calculate ideal daily burn (linear)
     - For each day in range:
       - Count completed items up to that day
       - remaining = total - completed
       - ideal = total - (dailyBurn * dayIndex)
     - Return array of { date, remaining, ideal }

   - getPersonalMetrics(userId, projectId, startDate, endDate):
     - Completed tasks and deliverables assigned to user
     - Daily completion counts
     - Comparison to project average (optional)

4. Create barrel export
  </action>
  <verify>
Run `bun run typecheck` - no TypeScript errors.
  </verify>
  <done>
Metrics service created with output metrics aggregation (by day, person, squad), velocity calculation, and burndown chart data.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create routes for uploads and metrics</name>
  <files>
    src/features/uploads/uploads.routes.ts
    src/features/metrics/metrics.routes.ts
    src/index.ts
  </files>
  <action>
Create REST endpoints for file uploads and metrics:

1. Create `src/features/uploads/uploads.routes.ts`:
   - Import Hono, zod, authMiddleware, visibilityMiddleware
   - Apply middleware

   Endpoints:
   - POST /presign - Get presigned upload URL
     - Body: { filename, contentType, targetType, targetId }
     - Call uploadsService.createUploadUrl
     - Return 201 with { uploadUrl, attachmentId, expiresAt }

   - POST /:attachmentId/confirm - Confirm upload completed
     - Call uploadsService.confirmUpload
     - Return 200 with { downloadUrl }

   - GET /:attachmentId/download - Get download URL
     - Call uploadsService.getDownloadUrl
     - Return 200 with { downloadUrl }

   - DELETE /:attachmentId - Delete attachment
     - Call uploadsService.deleteAttachment
     - Return 204

   - GET / - List attachments for target
     - Query: targetType, targetId
     - Call uploadsService.listAttachments
     - Return array of attachments

2. Create `src/features/metrics/metrics.routes.ts`:
   - Apply middleware

   Endpoints:
   - GET /output - Get output metrics
     - Query: projectId (required), startDate, endDate, squadId?
     - Parse dates with dayjs
     - Call metricsService.getOutputMetrics
     - Return OutputMetrics

   - GET /velocity - Get velocity over time
     - Query: projectId (required), periodDays? (default 7), numPeriods? (default 4)
     - Call metricsService.getVelocity
     - Return array of VelocityPeriod

   - GET /burndown - Get burndown chart data
     - Query: projectId (required), startDate, endDate, squadId?
     - Call metricsService.getBurndownData
     - Return array of BurndownPoint

   - GET /personal - Get personal metrics for current user
     - Query: projectId (required), startDate, endDate
     - Use c.get('userId') for current user
     - Call metricsService.getPersonalMetrics
     - Return personal metrics

3. Wire routes in `src/index.ts`:
   - Import uploadsRoutes from './features/uploads'
   - Import metricsRoutes from './features/metrics'
   - Mount at '/api/v1/uploads' and '/api/v1/metrics'
  </action>
  <verify>
Run `bun run typecheck` - no TypeScript errors.
Run `bun run lint` - no linting errors.
Run `bun run db:migrate` - migrations applied.
Test (without S3 configured - expect 503):
- POST /api/v1/uploads/presign returns 503 (S3 not configured) or 201 (if configured)
Test metrics (with some test data):
- GET /api/v1/metrics/output?projectId=xxx&startDate=2026-01-01&endDate=2026-02-05 returns metrics
  </verify>
  <done>
Uploads and metrics REST APIs complete. File uploads use S3 presigned URLs with graceful 503 when not configured. Metrics provide output counts, velocity, and burndown data.
  </done>
</task>

</tasks>

<verification>
1. POST /uploads/presign returns presigned URL when S3 configured
2. POST /uploads/presign returns 503 when S3 not configured (graceful degradation)
3. GET /metrics/output returns correct task and deliverable counts
4. GET /metrics/velocity returns velocity for each period
5. GET /metrics/burndown returns ideal and actual remaining work
6. Metrics are filtered by squadId when provided
</verification>

<success_criteria>
- Attachments table tracks upload status and S3 keys
- S3 presigned URLs work for upload and download
- Service handles missing S3 config gracefully (503)
- Output metrics aggregate completed work correctly
- Velocity calculates completions per time period
- Burndown calculates remaining vs ideal
- TypeScript compiles without errors
- Linter passes
</success_criteria>

<output>
After completion, create `.planning/phases/04-tasks-deliverables/04-04-SUMMARY.md`
</output>
